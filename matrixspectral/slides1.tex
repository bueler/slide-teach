% Copyright 2020  Ed Bueler

\documentclass[10pt,hyperref]{beamer}

\mode<presentation>
{
  \usetheme{Madrid}

  \usecolortheme{beaver}

  \setbeamercovered{transparent}
  
  \setbeamerfont{frametitle}{size=\large}
}

\setbeamercolor*{block title}{bg=red!10}
\setbeamercolor*{block body}{bg=red!5}

\usepackage[english]{babel}
\usepackage[latin1]{inputenc}
\usepackage{times}
\usepackage[T1]{fontenc}
% Or whatever. Note that the encoding and the font should match. If T1
% does not look nice, try deleting the line with the fontenc.

\usepackage{empheq}
\usepackage{animate}
\usepackage{xspace}
\usepackage{verbatim,fancyvrb}
\usepackage{hyperref}

% If you wish to uncover everything in a step-wise fashion, uncomment
% the following command: 
%\beamerdefaultoverlayspecification{<+->}

\newcommand{\bb}{\mathbf{b}}
\newcommand{\bc}{\mathbf{c}}
\newcommand{\br}{\mathbf{r}}
\newcommand{\bx}{\mathbf{x}}
\newcommand{\by}{\mathbf{y}}
\newcommand{\bv}{\mathbf{v}}
\newcommand{\bu}{\mathbf{u}}
\newcommand{\bw}{\mathbf{w}}

\newcommand{\grad}{\nabla}

\newcommand{\CC}{\mathbb{C}}
\newcommand{\RR}{\mathbb{R}}

\newcommand{\ddt}[1]{\ensuremath{\frac{\partial #1}{\partial t}}}
\newcommand{\ddx}[1]{\ensuremath{\frac{\partial #1}{\partial x}}}
\renewcommand{\t}[1]{\texttt{#1}}
\newcommand{\Matlab}{\textsc{Matlab}\xspace}
\newcommand{\Octave}{\textsc{Octave}\xspace}
\newcommand{\MO}{\Matlab}
\newcommand{\eps}{\epsilon}

\newcommand{\ip}[2]{\left<#1,#2\right>}

\newcommand{\MS}{\alert{MAKE SURE}\xspace}

\newcommand{\exer}[2]{\medskip\noindent \textbf{#1.}\quad #2}

\newcommand{\mfile}[1]{
\VerbatimInput[frame=single,label=\fbox{\scriptsize \textsl{\,#1\,}},fontfamily=courier,fontsize=\scriptsize]{#1}
}

\newcommand{\mfiletiny}[1]{
\VerbatimInput[frame=single,label=\fbox{\scriptsize \textsl{\,#1\,}},fontfamily=courier,fontsize=\tiny]{#1}
}

\AtBeginSection[]
{
  \begin{frame}<beamer>
    \frametitle{Outline}
    \tableofcontents[currentsection,hideallsubsections]
  \end{frame}
}

\title{Finite-dimensional spectral theory}

\subtitle{part I: $\CC^n$ as an inner-product space to the Schur decomposition}

\author{Ed Bueler}

\institute[MATH 617]{MATH 617 Functional Analysis}

\date{Spring 2020}

\begin{document}
\beamertemplatenavigationsymbolsempty

\begin{frame}
  \maketitle
\end{frame}


\begin{frame}{finite-dimensional spectral theory}

\begin{itemize}
\item these slides are about linear algebra, i.e.~vector spaces of finite dimension, and linear operators on those spaces
\item one definition of \emph{functional analysis} might be: ``rigorous extension of linear algebra concepts to infinite-dimensional topological vector spaces''
\item the \emph{spectrum} of a square matrix $A$ is its set of eigenvalues
    \begin{itemize}
    \item[$\circ$] there will be reminder below about the definition of eigenvalues
    \item[$\circ$] the spectrum $\sigma(A)$ is a subset of the complex plane $\CC$
        \begin{itemize}
        \item graphing $\sigma(A)$ gives the matrix $A$ a ``personality''
        \end{itemize}
    \end{itemize}
\item see part II of these slides for the spectral theorem and variations
\item good references for both parts of these slides:
    \begin{itemize}
    \item[$\circ$] L.~Trefethen \& D.~Bau, \emph{Numerical Linear Algebra}, SIAM Press 1997
    \item[$\circ$] G.~Strang, \emph{Introduction to Linear Algebra}, 5th ed., Wellesley-Cambridge Press, 2016
    \item[$\circ$] G.~Golub \& C.~van Loan, \emph{Matrix Computations}, 4th ed., Johns Hopkins University Press 2013
    \end{itemize}

\end{itemize}
\end{frame}


\begin{frame}{$\CC^n$ is an inner product space}

\begin{itemize}
\item we use complex numbers $\CC$ from now on
    \begin{itemize}
    \item[$\circ$] why? because eigenvalues can be complex even for a real matrix
    \item[$\circ$] if $\alpha=x+iy \in \CC$ then $\overline{\alpha} = x-iy$ is the \emph{conjugate}
    \end{itemize}
\item let $\CC^n$ be the space of (column) vectors with complex entries:
\footnotesize
    $$v = \begin{bmatrix}
    v_1 \\ \vdots \\ v_n
    \end{bmatrix}$$
\normalsize
\vspace{-2mm}
    \begin{itemize}
    \item[$\circ$] the \emph{hermitian conjugate} of $v\in\CC^n$ is the row vector $v^* = [\overline{v_1},\dots,\overline{v_n}]$
    \end{itemize}
\item an \emph{inner product} on $\CC^n$ is an almost-bilinear (\emph{sesquilinear}\footnote{This word is kind of a joke.  It means ``$1\frac{1}{2}$ linear".}) function
    $$\ip{\cdot}{\cdot}:\CC^n\times \CC^n \to \CC$$
with symmetry and positivity properties: \quad for all $u,v,w \in \CC^n$ and $\alpha\in \CC$,
    \begin{itemize}
    \item[$\circ$] $\ip{w}{u+v} = \ip{w}{u} + \ip{w}{v}$
    \item[$\circ$] $\ip{u}{\alpha v} = \alpha \ip{u}{v}$
    \item[$\circ$] $\ip{u}{v} = \overline{\ip{v}{u}}$
    \item[$\circ$] $\ip{u}{u} \ge 0$ and $\ip{u}{u}=0$ if and only if $u=0$
    \end{itemize}
\end{itemize}
\end{frame}


\begin{frame}{$\CC^n$ as an inner product space, cont.}

\begin{itemize}
\item note that the inner product is conjugate linear in the first position and linear in the second:
    \begin{itemize}
    \item[$\circ$] $\ip{u+v}{w} = \overline{\ip{w}{u+v}} = \overline{\ip{w}{u}} + \overline{\ip{w}{v}} = \ip{u}{w} + \ip{v}{w}$
    \item[$\circ$] $\ip{\alpha u}{v} =\overline{\ip{v}{\alpha u}} = \overline{\alpha} \overline{\ip{v}{u}} =\overline{\alpha} \ip{u}{v}$
    \end{itemize}
\item but the inner product is not abstract; it is just a matrix product on $\CC^n$:
    $$\ip{u}{v} = u^* v = \begin{bmatrix}
    \overline{u_1} & \cdots & \overline{u_n}
    \end{bmatrix} \begin{bmatrix}
    v_1 \\ \vdots \\ v_n
    \end{bmatrix}$$
\item \dots the slides below are a reminder of how matrix products and the Hermitian conjugate ($u^*$) work
\end{itemize}
\end{frame}


\begin{frame}{bases and matrices}

\begin{itemize}
\item a (finite) set of vectors $\{v_i\}_{i=1}^m \subset \CC^n$ is \emph{linearly-dependent} if there exist scalars $\alpha_i \in \CC$, not all zero, so that $\alpha_1 v_1 + \dots + \alpha_m v_m = 0$
    \begin{itemize}
    \item[$\circ$] a set of vectors is \emph{linearly-independent} if it is not linearly-dependent
    \end{itemize}
\item a finite set of vectors $\{v_i\}_{i=1}^m$ \emph{span} $\CC^n$ if for any $w\in \CC^n$ there exist scalars $\alpha_i$ so that $w = \alpha_1 v_1 + \dots + \alpha_m v_m$
\item \textbf{Lemma.}  If $\{v_i\}_{i=1}^m$ is linearly-independent then each $v_i$ is nonzero and $m \le n$.  If $\{v_i\}_{i=1}^m$ spans $\CC^n$ then $m \ge n$.
\item a finite set of vectors $\{v_i\}_{i=1}^m \subset \CC^n$ is a \emph{basis} if the set is linearly-independent and it spans $\CC^n$
    \begin{itemize}
    \item[$\circ$] by the Lemma, $m=n$
    \end{itemize}
\item a function $A:\CC^n \to \CC^n$ is \emph{linear} if $A(\alpha u+\beta v) = \alpha A(u) + \beta A(v)$
    \begin{itemize}
    \item[$\circ$] we call such a function a \emph{linear operator} and we write $Au=A(u)$
    \item[$\circ$] given a basis, one may represent a linear operator as a (square) \emph{matrix}
    \item[$\circ$] matrix multiplication is just function composition
    \end{itemize}
\item a matrix $A$ is \emph{invertible} if there exists a matrix $B$ so that $AB=BA=I$
\item \textbf{Lemma.} A matrix is invertible if and only if its columns form a basis.
\end{itemize}
\end{frame}

\begin{frame}{X}

\begin{itemize}
\item Y
\end{itemize}
\end{frame}

\begin{frame}{X}

\begin{itemize}
\item Y
\end{itemize}
\end{frame}

\end{document}

