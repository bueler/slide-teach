% Copyright 2023  Ed Bueler

\documentclass[10pt,hyperref]{beamer}

\mode<presentation>
{
  \usetheme{Madrid}

  \usecolortheme{beaver}

  \setbeamercovered{transparent}
  
  \setbeamerfont{frametitle}{size=\large}
}

\setbeamercolor*{block title}{bg=red!10}
\setbeamercolor*{block body}{bg=red!5}

\usepackage[english]{babel}
\usepackage[latin1]{inputenc}
\usepackage{times}
\usepackage[T1]{fontenc}
% Or whatever. Note that the encoding and the font should match. If T1
% does not look nice, try deleting the line with the fontenc.

\usepackage{empheq,bm,xspace,minted}
\usepackage{hyperref}

% If you wish to uncover everything in a step-wise fashion, uncomment
% the following command: 
%\beamerdefaultoverlayspecification{<+->}

\newcommand{\bb}{\mathbf{b}}
\newcommand{\bc}{\mathbf{c}}
\newcommand{\bbf}{\mathbf{f}}
\newcommand{\bl}{\bm{\ell}}
\newcommand{\br}{\mathbf{r}}
\newcommand{\bs}{\mathbf{s}}
\newcommand{\bx}{\mathbf{x}}
\newcommand{\by}{\mathbf{y}}
\newcommand{\bv}{\mathbf{v}}
\newcommand{\bu}{\mathbf{u}}
\newcommand{\bw}{\mathbf{w}}

\newcommand{\bzero}{\bm{0}}

\newcommand{\CC}{\mathbb{C}}
\newcommand{\RR}{\mathbb{R}}

\newcommand{\ddt}[1]{\ensuremath{\frac{\partial #1}{\partial t}}}
\newcommand{\ddx}[1]{\ensuremath{\frac{\partial #1}{\partial x}}}
\renewcommand{\t}[1]{\texttt{#1}}
\newcommand{\Matlab}{\textsc{Matlab}\xspace}
\newcommand{\Octave}{\textsc{Octave}\xspace}
\newcommand{\eps}{\epsilon}

\newcommand{\twovect}[4]{\ensuremath{{#1}_{#2} =
                            \begin{bmatrix} #3 \\ #4 \end{bmatrix}}}

\newcommand{\ftt}[1]{{\color{blue} \texttt{#1}}}

\newcommand{\optimaldef}{
\begin{definition}
an algorithm for computing a function on a class of problems, which acts on floating-point data of size $N$, is \emph{optimal} if it requires
   $$O(N) \qquad \text{ or } \qquad O(N\log N) \qquad \text{ flops}$$
\end{definition}
}


\title{Which linear systems can be solved optimally?}

\author{Ed Bueler}

\institute[]{UAF Math 692 Scalable Seminar}

\date{Spring 2023}


\begin{document}

\begin{frame}
  \maketitle
\end{frame}

\begin{frame}{Outline}
  %\tableofcontents[hideallsubsections]
  \tableofcontents
\end{frame}

\section{how fast is the basic matrix-vector product operation $z=Ax$?}

\newcommand{\bulletax}{\begin{bmatrix} \bullet \\ \bullet \\ \bullet \\ \bullet \end{bmatrix} = \begin{bmatrix} \bullet & \bullet & \bullet \\ \bullet & \bullet & \bullet \\ \bullet & \bullet & \bullet \\ \bullet & \bullet & \bullet \end{bmatrix} \begin{bmatrix} \bullet \\ \bullet \\ \bullet \end{bmatrix}}

\begin{frame}{matrix-vector products}
\begin{itemize}
\item the life-goal of a matrix $A \in \RR^{m\times n}$ is to act on (=multiply) vectors $x \in \RR^n$, yielding $z\in\RR^m$:
    $$z = Ax \qquad\quad \bulletax$$
\item this is a simple and familiar operation:
    $$(Ax)_i = \sum_{j=0}^{n-1} a_{ij} x_j \qquad \text{ for } i=0,\dots,m-1$$

    \begin{itemize}
    \item[$\circ$] note: I will index rows and columns starting from 0 in this talk
    \item[$\circ$] note: by default, vectors in $\RR^n$ are column vectors
    \end{itemize}
\item how fast is matrix-vector multiplication?
\item what is its (\emph{algorithmic}) \emph{complexity}?
\end{itemize}
\end{frame}

\begin{frame}[fragile]
\frametitle{\texttt{matvec}}
\begin{itemize}
\item \phantom{actually,} this talk is based on genuine \phantom{pseudo}codes in Python\phantom{-ish}:
\end{itemize}
\begin{center}
\begin{minipage}{0.7\textwidth}
\begin{minted}[fontsize=\small]{python}
def matvec(A,x):
    from numpy import zeros, shape
    [m,n] = shape(A)
    z = zeros((m,1))
    for i in range(m):
        s = 0.0
        for j in range(n):
            s += A[i][j] * x[j]
        z[i] = s
    return z
\end{minted}
\end{minipage}
\end{center}
\end{frame}

\begin{frame}[fragile]
\frametitle{\texttt{matvec}}
\begin{itemize}
\item actually, this talk is based on genuine pseudocodes in Python-ish:
\end{itemize}
\begin{center}
\begin{minipage}{0.7\textwidth}
\begin{minted}[fontsize=\small]{python}
def matvec(A,x):
    for i = 0 to m-1:
        s = 0.0
        for j = 0 to n-1:
            s += A[i][j] * x[j]
        z[i] = s
    return z



\end{minted}
\end{minipage}
\end{center}
\end{frame}


\begin{frame}[fragile]
\frametitle{\texttt{matvec} flops}
\begin{center}
\begin{minipage}{0.7\textwidth}
\begin{minted}[fontsize=\small]{python}
def matvec(A,x):
    for i = 0 to m-1:
        s = 0.0
        for j = 0 to n-1:
            s += A[i][j] * x[j]
        z[i] = s
    return z
\end{minted}
\end{minipage}
\end{center}

\begin{itemize}
\item this \ftt{matvec} does exactly $2mn$ floating point operations (\emph{flops})
    \begin{itemize}
    \item[$\circ$] $n$ additions and $n$ multiplications for each of $m$ entries of result vector $Ax$
    \end{itemize}
\item complexity in big-O notation:
    \begin{itemize}
    \item[$\circ$] $O(mn)$ flops
    \item[$\circ$] $O(mn)$ storage (including inputs $A$ and $x$)
    \item[$\circ$] $O(mn)$ time (messy?)
    \end{itemize}
\end{itemize}
\end{frame}


\subsection{definition of ``optimal''}

\begin{frame}{my definition of \emph{optimal}}

\begin{itemize}
\item I will throw around ``optimal'' a lot in this talk
\end{itemize}

\optimaldef

\begin{itemize}
\item this means there exists $C$ so that for all problems, of any size $N$,
   $$(\text{flops}) \le C\, N \qquad \text{ or } \qquad (\text{flops}) \le C\, N\log N$$

    \begin{itemize}
    \item[$\circ$] quantifier order matters: \quad $\exists C \,\, \forall \text{ problems} \,\, \forall N \,\,  \dots$
    \end{itemize}
\item is \ftt{matvec} optimal?
\end{itemize}
\end{frame}


\begin{frame}{is \texttt{matvec} optimal?}

\hfill
{\scriptsize $\displaystyle \bulletax$}

\vspace{2mm}

\hfill
{\scriptsize $z = A x$} \hspace{17mm}

\vspace{-8mm}
\begin{itemize}
\item is \ftt{matvec} optimal?
\item it depends on what are the \alert{data} and the \alert{problems}!
\end{itemize}

\begin{enumerate}
\item<2->[1.] if the \alert{data $=$ vector $x$} ($N=n$), and we consider \alert{any matrix $A\in\RR^{m\times n}$ for which multiplication is valid}, then it \textbf{\emph{is not} optimal $O(N)$}
    \begin{itemize}
    \item[$\circ$] $2mn = 2m N \nleq C N$ for all problems \hfill $\gets$ \emph{$m$ depends on the problem}
    \end{itemize}
\item<3->[2.] if the \alert{data $=$ vector $x$} ($N=n$), and we consider a \alert{all matrices $A$ with (fixed) $m$ rows}, then it \textbf{\emph{is} optimal $O(N)$}, but the constant can be big
    \begin{itemize}
    \item[$\circ$] $2mn = 2m N \leq C N$ for $C=m$
    \end{itemize}
\item<4->[3.] if the \alert{data $=$ matrix $A$} ($N=mn$), and we consider \alert{any $x$}, then it \textbf{\emph{is} optimal $O(N)$}
    \begin{itemize}
    \item[$\circ$] $2mn = 2 N \leq C N$ for $C=2$
    \end{itemize}
\item<5>[4.] if the \alert{data $=$ vector $x$} ($N=n$), and we consider \alert{any tridiagonal matrix $A$}, then it \textbf{\emph{is} optimal $O(N)$}, assuming we don't do the zero multiplications
    \begin{itemize}
    \item[$\circ$] $2\cdot 3\cdot n = 6 N \leq C N$ for $C=6$
    \end{itemize}
\end{enumerate}
\end{frame}


\newcommand{\bulletaxtri}{\begin{bmatrix} \bullet \\ \bullet \\ \bullet \\ \bullet \end{bmatrix} = \begin{bmatrix} \bullet & \bullet & & \\ \bullet & \bullet & \bullet & \\ & \bullet & \bullet & \bullet \\ & & \bullet & \bullet \end{bmatrix} \begin{bmatrix} \bullet \\ \bullet \\ \bullet \\ \bullet \end{bmatrix}}

\begin{frame}[fragile]
\frametitle{tridiagonal matrix-vector product}

\begin{itemize}
\item the tridiagonal case is actually a different algorithm

\bigskip

\hfill
{\scriptsize $\displaystyle \bulletaxtri$}

\begin{center}
\begin{minipage}{0.8\textwidth}
\begin{minted}[fontsize=\small]{python}
def matvec_tri(A,x):
    z[0] = A[0][0] * x[0] + A[0][1] * x[1]
    for i = 1 to m-2:
        s = 0.0
        for j = i-1 to i+1:
            s += A[i][j] * x[j]
        z[i] = s
    z[m-1] = A[m-1][m-2] * x[m-2] + A[m-1][m-1] * x[m-1]
    return z
\end{minted}
\end{minipage}
\end{center}

\bigskip
\item this algorithm does $O(n)$ flops
\end{itemize}
\end{frame}


\begin{frame}{regarding optimal algorithms}

\begin{itemize}
\item I will stick to my definition of ``optimal''!
\item however, it is fair to stop me and ask ``what is the data?'' or ``what is the class of problems?'' at any time
    \begin{itemize}
    \item[$\circ$] because whether an algorithm is optimal depends on an agreement regarding which is the data and which is the problem class
    \end{itemize}
\item also, it is fair to wonder if flops are a good metric for modern computers
    \begin{itemize}
    \item[$\circ$] but every other metric is messier?
\only<1>{
    \item[$\circ$] \emph{put up or shut up!}
}
\only<2>{
    \item[$\circ$] perhaps give a talk using another metric?
}
    \end{itemize}
\end{itemize}

\optimaldef
\end{frame}


\AtBeginSection[]
{
  \begin{frame}<beamer>
    \frametitle{Outline}
    %\tableofcontents[currentsection,hideallsubsections]
    \tableofcontents[currentsection]
  \end{frame}
}

\section{complexity of Gauss elimination for linear systems $Ax=b$}

\begin{frame}{y}

\begin{itemize}
\item x
\end{itemize}
\end{frame}


\section{tridiagonal and other banded matrices}

\begin{frame}{y}

\begin{itemize}
\item x
\end{itemize}
\end{frame}


\section{circulant matrices}

\begin{frame}{y}

\begin{itemize}
\item x
\end{itemize}
\end{frame}


\section{sparse storage}

\begin{frame}{y}

\begin{itemize}
\item x
\end{itemize}
\end{frame}


\section{paradigm: preconditioned Krylov iterations}

\begin{frame}{y}

\begin{itemize}
\item x
\end{itemize}

\hfill \includegraphics[width=0.2\textwidth]{images/akrylov.jpg}
\end{frame}


\section{multigrid: a teaser}

\begin{frame}{y}

\begin{itemize}
\item x
\end{itemize}
\end{frame}


\begin{frame}{references}

\begin{columns}
\begin{column}{0.85\textwidth}
\begin{itemize}
{\small
\item[] \textbf{A.~Brandt (1977)}. \emph{Multi-level adaptive solutions to boundary-value problems}, Mathematics of Computation 31 (138), 333--390
    \begin{itemize}
    \item[$\circ$] the guru of multigrid should be better known
    \end{itemize}
\item[] \textbf{W.~Briggs, V.~E.~Henson, \& S.~McCormick (2000)}.  \emph{A Multigrid Tutorial}, 2nd ed., SIAM Press, Philadelphia
\item[] \textbf{E.~Bueler (2021)}. \emph{PETSc for Partial Differential Equations}, SIAM Press, Philadelphia
    \begin{itemize}
    \item[$\circ$] optimal PDE solvers, multigrid, C and Python constructions
    \end{itemize}
\item[] \textbf{G.~Golub \& C.~van Loan (2013)}. \emph{Matrix Computations}, 4th ed., Johns Hopkins University Press, Baltimore
    \begin{itemize}
    \item[$\circ$] algorithms, banded \& circulant matrices, sparse storage
    \end{itemize}
\item[] \textbf{L.~Trefethen \& D.~Bau (2022)}. \emph{Numerical Linear Algebra}, 25th anniversary ed., SIAM Press, Philadelphia
    \begin{itemize}
    \item[$\circ$] clear thinking on linear systems
    \end{itemize}
\item[] \textbf{U.~Trottenberg, C.~Oosterlee, \& A. Schuller (2001)}.  \emph{Multigrid}, Elsevier, Oxford
}
\end{itemize}
\end{column}
\begin{column}{0.15\textwidth}
\hfill \includegraphics[width=\textwidth]{images/abrandt.jpg}

\vspace{7mm}
\hfill \includegraphics[width=0.8\textwidth]{images/bueler.jpg}

\bigskip
\hfill \includegraphics[width=0.8\textwidth]{images/trefethenbau.jpg}

\vspace{5mm}
\end{column}
\end{columns}
\end{frame}


\end{document}

